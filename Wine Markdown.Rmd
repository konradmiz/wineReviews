---
title: "Wine Word Clouds"
author: "Konrad Miziolek"
date: "August 18, 2018"
output: html_document
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(ggrepel)
library(tidytext)
library(stringr)
```

## Data Import

Though there are ~150,000 reviews, there are only ~95,000 unique ones. 

```{r}
wine <- read_csv("Wine 150k reviews.csv") %>%
  select(-X1) %>%
  mutate(country = as.factor(country), 
         province = as.factor(province),
         region_1 = as.factor(region_1),
         region_2 = as.factor(region_2),
         variety = as.factor(variety),
         winery = as.factor(winery)) %>%
  distinct()
```

```{r}
summary(wine)
```

Most variables are non-sparse, i.e. have many observations. Notably price is missing from ~ 9% of the observations. There are some other issues to address as well: California is listed as both a province and a region_1; I'm sure that there are other regions that have simliar issues. For more detailed analyses of region-based data that will have to be dealt with. However, since I'm primarily interested in doing a wordcloud for now, that is the direction I'll be going below. 

## Grouping descriptions of varieties together

My end goal is  to have a word cloud for different varieties of wine. Because there are `r length(unique(wine$variety))` varieties, and only finite screen space, I've chosen to select only the top 12 most rated wines. 

### Filtering the top 12-most rated wine varieties

This returns a vector of the most popular (most-reviewed) wines with length 12

```{r}
top_12_vars <- wine %>%
  group_by(variety) %>%
  summarise(N = n()) %>%
  top_n(12, N) %>%
  mutate(variety = as.character(variety)) %>%
  pull(variety)
```

### Getting the descriptions for each of these varieties

I filter the dataset so that the variety is one of the popular ones found above, and then collapse all of the users' descriptions
into one long string ('bag of words') per variety of wine. 

```{r}
variety_descriptions <- wine %>%
  filter(variety %in% top_12_vars) %>%
  group_by(variety) %>%
  mutate(description = paste(description, collapse = " "),
         num_reviews = n()) %>% 
  select(variety, description, num_reviews) %>%
  distinct(variety, .keep_all = TRUE) %>%
  ungroup()

```

These varities have been described extensively: below is the number of characters in the total description of these wines.

```{r}
data_frame(Variety = variety_descriptions$variety,
           Reviews = variety_descriptions$num_reviews,
           Nchar = nchar(variety_descriptions$description)) %>%
  arrange(Variety)

```


However, the bag of words for each variety is tricky to deal with. To make the analysis easier, the data needs to be tidied: each row in the dataframe should correspond to a {variety, word} observation. Since I'm interested in word frequency for each variety I also aggregate the counts here. 

```{r}
unnested_tokens <- variety_descriptions %>%
  unnest_tokens(word, description) %>%
  group_by(variety, word) %>%
  count()

nrow(unnested_tokens)
```

This provides a very long dataframe: `r scales::comma(nrow(unnested_tokens))` rows and `r ncol(unnested_tokens)` rows.

I then remove common English words ('the', 'and', 'but') from the reviews. These words are known as stop words and don't really contribute anything to the differences in description between the wines. Additionally, it's common in reviews to cite the name of what is being reviewed; I want to remove the most common words that could be thought of as wine-specific stop words: the names of the wines, and two throw-in words common in most of the reviews. I also remove numeric values: years, prices, ordinal numbers. 

```{r}
wine_words <- c("wine", "flavors")
wine_types <- c(unique(tolower(wine$variety)), "pinot", "noir", "syrahs")

without_stop_words <- unnested_tokens %>%
  anti_join(tidytext::stop_words) %>%
  filter(!word %in% regex(wine_words) & 
          ! word %in% regex(wine_types) &
         !str_detect(word, "[[:digit:]]")) %>%
  ungroup() %>%
  mutate(variety = as.character(variety))

```

Sometimes the same word is repeated with a slighly different ending (e.g. strawberry vs strawberries). The process of removing those is called de-stemming. De-stemming a word can oftentimes return a non-word string back; I do want to keep the full words. To do so, I create a new variable for the word stem and count the number of observations of that word stem by variety. I then keep the original word with the highest count that has that word stem. Thus "strawberry" and "strawberries" are counted as the same word and I can include their sum frequency of occurence in just the word "strawberry."   

```{r}
stemmed_words <- without_stop_words %>%
  mutate(word_stem = SnowballC::wordStem(word)) %>%
  group_by(word_stem, variety) %>%
  mutate(N = sum(n)) %>%
  ungroup() %>%
  group_by(variety, word_stem) %>%
  filter(n == max(n)) %>%
  distinct(variety, word_stem, .keep_all = TRUE) %>%
  select(-n, -word_stem)
```

## Most common words by variety


```{r}
wine_subset <- stemmed_words %>%
  group_by(variety) %>%
  top_n(10, N)

ggplot(wine_subset, aes(x = reorder(word, N), y = N)) + 
  geom_bar(stat = "identity") + 
  scale_y_log10() + 
  facet_wrap(.~ variety, scales = "free") + 
  coord_flip() + 
  labs(x = "Word")
```
## Wordcloud

Some words are very common between varieties (fruit, cherry, tannins) and so would be boring to see on a wordcloud for each wine. Meanwhile some words don't show up frequently outside of that variety (Chardonnay and pineapple, Sauvignon Blanc and grapefruit, Syrah and pepper, etc). These words are better at distinguishing different wine varieties than common shared words, so it would be nice to distinguish them better. One way of quantifying this is through TF-IDF (text-frequency/inter-document frequency). Words that are common in each corpus (here defined as a variety) are weighted low, while words that are frequent in one corpus but not in others are weighted higher. For each variety, the 75 words with the highest TF-IDF score are chosen.

```{r}
wine_tf_idf <- stem_word_counts %>%
  bind_tf_idf(word, variety, N) %>%
  group_by(variety) %>%
  top_n(75, tf_idf) %>%
  ungroup() 
```

### Wordcloud libraries

While there exists a great wordcloud library in R (suitably named ``wordcloud``), it uses base R graphics and doesn't support features such as facetting by variety that I'm looking for. On the other hand, ggplot2 does not natively have a wordcloud ability, but there is a workaround with ``geom_text()`` and especially the extremely helpful extension ``ggrepel::geom_text_repel()``. With some inspiration from http://mhairihmcneill.com/blog/2016/04/05/wordclouds-in-ggplot.html and https://bridgewater.wordpress.com/2012/04/16/word-cloud-alternatives/ I've created my own way of using ``ggplot2`` and ``ggrepel``.


Mhairi set the x and y coordinates to 1, relying on `ggrepel::geom_text_repel()`` to nudge the text into the appropriate positions, but the wordclouds were a little too diffuse for me. Instead I sample the normal distribution for both x and y coordinates, leading to a tight bunch in the center with some words farther on the boundaries of the screen. 


I also size the words (and later set the transparency) by their fraction of their variety's TF-IDF. Words that are important for each variety are therefore larger and easier to see. The alternative way of sizing is to ignore variety and simply have the most distinctive words stand out. My current method gives each wine variety more parity; I may decide to switch over later. 

I add an angle to the words as well (uniform randoml sampling of 0 or 90 degree rotation) but I got too much overlap in the labels so I've taken out that argument from the plotting function now. 

```{r}
wine_plot_data <- wine_tf_idf %>%
  select(-tf, -idf) %>%
  mutate(x = rnorm(n = nrow(.)),
         y = rnorm(n = nrow(.)),
         angle = sample(x = c(0, 90), size = nrow(.), replace = TRUE)) %>%
  group_by(variety) %>%
  mutate(size = tf_idf/sum(tf_idf))
```

## The plot

By specifying the segment size is 0 and the point padding is NA, I get non-overlapping text (as much as is possible in the number of iterations). 

```{r}
ggplot(wine_plot_data, aes(x, y, label = word)) + 
  theme_bw() + 
  geom_text_repel(aes(size = size, alpha = size), segment.size = 0, # angle = angle
                  force = 10, max.iter = 25000, point.padding = NA) + 
  facet_wrap(~variety, scales = "free") + 
  theme(axis.text = element_blank(),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  guides(size = FALSE) + 
  guides(alpha = FALSE) #+ 
  #ggsave("Top Wine Wordclouds TF-IDF.png", width = 12, height = 8, units = "in")
```

